# -*- coding: utf-8 -*-
"""
å®Œæ•´ç‰ˆï¼šè‚¡ç¥¨å¤ç›˜ä¸æ‰¹æ¬¡è¶‹åŠ¿è¿½è¸ªï¼ˆStreamlit åº”ç”¨ï¼‰
- æ”¯æŒå¤šä¸ª Excel æ–‡ä»¶ï¼ˆå¤šæ‰¹æ¬¡ï¼‰ä¸Šä¼ 
- è‡ªåŠ¨æ¸…æ´— / Arrow å‹å¥½åŒ–å¤„ç†
- è¿ç»­ä¸Šæ¶¨åˆ¤æ–­ï¼šstrict / ma_aboveï¼ˆ5æ—¥å‡çº¿ä¸Šï¼‰
- ä¿å­˜æ¯æ—¥ç»“æœåˆ°æœ¬åœ°å†å² stock_trend_history.csv
- æ‰¹æ¬¡å¸‚åœºçƒ­åº¦è¿½è¸ªï¼ˆbatch_trend.csvï¼‰
- ä¸ªè‚¡å¤šæ—¥è½¨è¿¹å¯è§†åŒ–ï¼ˆæ–œç‡ vs è¿ç»­ä¸Šæ¶¨ï¼‰
- ç•Œé¢äº¤äº’ï¼šä¾§è¾¹æ å‚æ•°ã€é˜ˆå€¼ã€é€‰æ‹©è‚¡ç¥¨ç­‰
- æ‰€æœ‰ä¸»è¦åˆ†ææ¨¡å—æ”¯æŒæŠ˜å /å±•å¼€
"""

import os
import logging
import datetime
from collections import Counter
import tempfile

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import streamlit as st

# ========== åŸºç¡€é…ç½® ==========
# ä¿®å¤ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
try:
    # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
    matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS', 'SimSun']
    matplotlib.rcParams['axes.unicode_minus'] = False
except:
    pass

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(filename="analysis_debug.log",
                    level=logging.DEBUG,
                    format="%(asctime)s [%(levelname)s] %(message)s")

# Streamlit é¡µé¢é…ç½®
st.set_page_config(layout="wide", page_title="è‚¡ç¥¨å¤ç›˜ä¸æ‰¹æ¬¡è¿½è¸ª")
st.title("ğŸ“ˆ è‚¡ç¥¨å¤ç›˜ä¸æ‰¹æ¬¡è¿½è¸ªï¼ˆæ•´åˆç‰ˆï¼‰")

# ========== å¯è°ƒæ•´å‚æ•° ==========

# åˆ—åé…ç½®ï¼ˆè‹¥ä½ çš„ Excel è¡¨åˆ—åä¸åŒï¼Œå¯åœ¨è¿™é‡Œä¿®æ”¹ï¼‰
code_col = "è‚¡ç¥¨ä»£ç "
name_col = "è‚¡ç¥¨ç®€ç§°"

# ä¾§è¾¹æ å‚æ•°é…ç½®
st.sidebar.header("åˆ†æå‚æ•°")
# è¿ç»­ä¸Šæ¶¨åˆ¤æ–­æ¨¡å¼é€‰æ‹©
up_trend_mode = st.sidebar.selectbox(
    "è¿ç»­ä¸Šæ¶¨åˆ¤æ–­æ¨¡å¼",
    ["strict", "ma_above"],
    format_func=lambda x: {
        "strict": "ğŸ”´ ä¸¥æ ¼è¿ç»­ä¸Šæ¶¨ï¼šæ¯æ—¥æ”¶ç›˜ä»·å¿…é¡»é«˜äºå‰ä¸€æ—¥",
        "ma_above": "ğŸŸ¢ å®½æ¾è¿ç»­ä¸Šæ¶¨ï¼šæ”¶ç›˜ä»·ä½äºå‡çº¿ä¹‹ä¸Š"
    }[x]
)

# æ–œç‡é˜ˆå€¼æ»‘å—
slope_threshold = st.sidebar.slider("æœ€å°æ–œç‡é˜ˆå€¼(%)", 0.1, 5.0, 1.0, step=0.1)
# æ”¶ç›˜ä»·å¤©æ•°è¾“å…¥
close_days = st.sidebar.number_input("æ”¶ç›˜ä»·å¤©æ•° (ç”¨äºè¿ç»­åˆ¤æ–­)", value=5, min_value=2)
# è¡¨å¤´è¡Œæ•°é…ç½®ï¼ˆç”¨äºå¤æ‚è¡¨æ ¼ï¼‰
header_rows = st.sidebar.number_input("è¡¨å¤´è¡Œæ•° (å¤æ‚è¡¨æ ¼ç”¨)", value=1, min_value=1)
# è·³è¿‡Excelå‰å‡ è¡Œè¯´æ˜æ–‡å­—
skip_rows = st.sidebar.number_input("è·³è¿‡Excelå‰å‡ è¡Œè¯´æ˜æ–‡å­—", value=0, min_value=0)
# æ¦‚å¿µåˆ—åé…ç½®
concept_col_name = st.sidebar.text_input("æ¦‚å¿µåˆ—åï¼ˆå¯é€‰ï¼‰", value="æ‰€å±æ¦‚å¿µ")

# æ–‡ä»¶è·¯å¾„é…ç½®
HISTORY_FILE = "stock_trend_history.csv"
LAST_BATCH_FILE = "last_batch.csv"
BATCH_TREND_FILE = "batch_trend.csv"

# ========== å·¥å…·å‡½æ•° ==========

def make_arrow_safe(df: pd.DataFrame) -> pd.DataFrame:
    """ä¿®æ­£ DataFrame ä»¥é˜²æ­¢ Streamlit / Arrow æŠ¥é”™ã€å¹¶åšåŸºæœ¬æ¸…æ´—"""
    df = df.copy()
    # æ›¿æ¢å„ç§ç©ºå€¼è¡¨ç¤º
    df.replace(['-', '--', 'â€”', 'ç©ºå€¼', 'null', 'None', '', 'NaN', 'nan', 'æ— '], np.nan, inplace=True)
    # å¤„ç†æ–‡æœ¬åˆ—
    for c in df.select_dtypes(include=['object']).columns:
        try:
            df[c] = df[c].astype(str).str.strip().replace({'nan': np.nan, 'None': np.nan})
        except Exception:
            logging.debug(f"make_arrow_safe strip failed for {c}", exc_info=True)
    # æ•°å€¼åˆ—è½¬æ¢
    numeric_hint = ['%', 'æ–œç‡', 'å æ¯”', 'æ¶¨', 'è·Œ', 'ä»·', 'å‡çº¿', 'close', 'price']
    for col in df.columns:
        try:
            if any(k in str(col) for k in numeric_hint):
                df[col] = pd.to_numeric(df[col], errors='coerce')
        except Exception:
            logging.debug(f"make_arrow_safe to_numeric failed for {col}", exc_info=True)
    # æœ€ç»ˆæ¸…ç†
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).replace({'nan': np.nan})
    return df

def check_strict_continuous_up(closes, close_days):
    """ä¸¥æ ¼è¿ç»­ä¸Šæ¶¨åˆ¤æ–­ï¼šæ¯æ—¥æ”¶ç›˜ä»·å¿…é¡»é«˜äºå‰ä¸€æ—¥"""
    if len(closes) < close_days:
        return False, f"æ•°æ®ä¸è¶³: {len(closes)}/{close_days}"
    if any(price <= 0 for price in closes):
        return False, "å­˜åœ¨æ— æ•ˆä»·æ ¼(<=0)"
    # æ£€æŸ¥æ˜¯å¦è¿ç»­ä¸Šæ¶¨
    is_up = all(closes[i] > closes[i-1] for i in range(1, len(closes)))
    # ç”Ÿæˆè¯¦ç»†åˆ¤æ–­ä¿¡æ¯
    details = [f"ç¬¬{i+1}æ—¥:{closes[i]:.2f} > ç¬¬{i}æ—¥:{closes[i-1]:.2f} = {closes[i] > closes[i-1]}" for i in range(1, len(closes))]
    return is_up, '\n'.join(details)

def check_ma_above_continuous_up(closes, ma_values, close_days):
    """å®½æ¾è¿ç»­ä¸Šæ¶¨åˆ¤æ–­ï¼šæ”¶ç›˜ä»·ä½äºå‡çº¿ä¹‹ä¸Š"""
    if len(closes) < close_days or len(ma_values) < close_days:
        return False, f"æ•°æ®ä¸è¶³: æ”¶ç›˜{len(closes)}/å‡çº¿{len(ma_values)}/{close_days}"
    if any(price <= 0 for price in closes):
        return False, "å­˜åœ¨æ— æ•ˆä»·æ ¼(<=0)"
    # æ£€æŸ¥æ˜¯å¦éƒ½åœ¨å‡çº¿ä¹‹ä¸Š
    is_above_ma = all(closes[i] >= ma_values[i] for i in range(len(closes)))
    # ç”Ÿæˆè¯¦ç»†åˆ¤æ–­ä¿¡æ¯
    details = [f"ç¬¬{i+1}æ—¥: æ”¶ç›˜{closes[i]:.2f} â‰¥ å‡çº¿{ma_values[i]:.2f} = {closes[i] >= ma_values[i]}" for i in range(len(closes))]
    return is_above_ma, '\n'.join(details)

def safe_calculate_price_changes(closes):
    """å®‰å…¨è®¡ç®—ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”"""
    price_changes = []
    for i in range(1, len(closes)):
        if closes[i-1] > 0:
            change = (closes[i] - closes[i-1]) / closes[i-1] * 100
            price_changes.append(change)
        else:
            price_changes.append(0)
    return price_changes

def append_history_batch(result_df, history_file=HISTORY_FILE):
    """å°†å½“å‰æ‰¹æ¬¡ç»“æœè¿½åŠ åˆ°å†å²æ–‡ä»¶"""
    df_to_save = result_df.copy()
    df_to_save['æ—¥æœŸ'] = df_to_save['æ—¥æœŸ'].astype(str)
    if os.path.exists(history_file):
        try:
            existing = pd.read_csv(history_file, dtype=str)
        except Exception:
            existing = pd.read_csv(history_file, dtype=str, encoding='utf-8')
        # åˆå¹¶å¹¶å»é‡
        combined = pd.concat([existing, df_to_save], ignore_index=True)
        combined = combined.drop_duplicates(subset=['æ—¥æœŸ','è‚¡ç¥¨ä»£ç '], keep='last')
        combined.to_csv(history_file, index=False, encoding='utf-8-sig')
        history_df = combined
    else:
        df_to_save.to_csv(history_file, index=False, encoding='utf-8-sig')
        history_df = df_to_save
    # å°è¯•è½¬æ¢æ–œç‡åˆ—ä¸ºæ•°å€¼ç±»å‹
    try:
        history_df['æ–œç‡(%)'] = pd.to_numeric(history_df['æ–œç‡(%)'], errors='coerce')
    except Exception:
        pass
    return history_df

def load_history(history_file=HISTORY_FILE):
    """åŠ è½½å†å²æ•°æ®"""
    if os.path.exists(history_file):
        try:
            h = pd.read_csv(history_file, parse_dates=['æ—¥æœŸ'], infer_datetime_format=True)
            return h
        except Exception:
            try:
                h = pd.read_csv(history_file, dtype=str)
                if 'æ—¥æœŸ' in h.columns:
                    h['æ—¥æœŸ'] = pd.to_datetime(h['æ—¥æœŸ'], errors='coerce')
                return h
            except Exception:
                return pd.DataFrame()
    else:
        return pd.DataFrame()

def build_stock_data_map_from_df(df):
    """ä»DataFrameæ„å»ºè‚¡ç¥¨æ•°æ®æ˜ å°„"""
    close_cols, ma_cols = [], []
    # è¯†åˆ«æ”¶ç›˜ä»·å’Œå‡çº¿åˆ—
    for c in df.columns[2:]:
        col_lower = str(c).lower()
        if "æ”¶ç›˜ä»·" in col_lower or "close" in col_lower:
            close_cols.append(c)
        elif "å‡çº¿" in col_lower or "ma" in col_lower:
            ma_cols.append(c)
    
    stock_data_map = {}
    for idx, row in df.iterrows():
        try:
            code = str(row[df.columns[0]])
            name = str(row[df.columns[1]])
        except Exception:
            continue
        
        # æå–æ”¶ç›˜ä»·æ•°æ®
        closes = []
        for c in close_cols:
            val = row.get(c, np.nan)
            if pd.notna(val):
                val_str = str(val).replace(',', '').replace('â€”', '').replace('--', '').strip()
                if val_str in ["", "NaN", "None", "null"]:
                    continue
                try:
                    price = float(val_str)
                    if price > 0:
                        closes.append(price)
                except:
                    continue
        closes = closes[::-1]  # åè½¬é¡ºåºï¼ˆä»æ—§åˆ°æ–°ï¼‰
        closes = np.array(closes, dtype=float)
        
        # æå–å‡çº¿æ•°æ®
        ma_values = []
        if ma_cols:
            for c in ma_cols:
                val = row.get(c, np.nan)
                if pd.notna(val):
                    val_str = str(val).replace(',', '').replace('â€”', '').replace('--', '').strip()
                    if val_str in ["", "NaN", "None", "null"]:
                        continue
                    try:
                        ma = float(val_str)
                        if ma > 0:
                            ma_values.append(ma)
                    except:
                        continue
            ma_values = ma_values[::-1]
            ma_values = np.array(ma_values, dtype=float)
        else:
            # å¦‚æœæ²¡æœ‰å‡çº¿æ•°æ®ï¼Œè®¡ç®—å±€éƒ¨å¹³å‡å€¼
            ma_days = min(5, len(closes))
            if len(closes) > 0:
                ma_values = np.array([np.mean(closes[max(0, i-ma_days+1):i+1]) for i in range(len(closes))])
            else:
                ma_values = np.array([])
        
        stock_data_map[code] = {'name': name, 'closes': closes.copy(), 'ma_values': ma_values.copy()}
    return stock_data_map

def generate_ths_link(stock_code):
    """ç”ŸæˆåŒèŠ±é¡ºæ“ä½œæŒ‡å—"""
    # åˆ¤æ–­å¸‚åœºç±»å‹
    if stock_code.startswith('6'):
        market_prefix = 'SH'
    else:
        market_prefix = 'SZ'
    
    # è¿”å›æ“ä½œæŒ‡å—ï¼Œä¸å†è¿”å›ç½‘é¡µé“¾æ¥
    return f"åœ¨åŒèŠ±é¡ºä¸­è¾“å…¥: {stock_code} ç„¶åæŒ‰å›è½¦æŸ¥çœ‹Kçº¿"

def get_chinese_font():
    """è·å–ä¸­æ–‡å­—ä½“è·¯å¾„ - ä¿®å¤ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜"""
    # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
    font_candidates = [
        # Windows å­—ä½“
        'C:/Windows/Fonts/simhei.ttf',  # é»‘ä½“
        'C:/Windows/Fonts/simsun.ttc',  # å®‹ä½“
        'C:/Windows/Fonts/msyh.ttc',    # å¾®è½¯é›…é»‘
        'C:/Windows/Fonts/simkai.ttf',  # æ¥·ä½“
        
        # macOS å­—ä½“
        '/System/Library/Fonts/PingFang.ttc',
        '/Library/Fonts/Arial Unicode.ttf',
        '/System/Library/Fonts/STHeiti Light.ttc',
        
        # Linux å­—ä½“
        '/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf',
        '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',
        
        # å¸¸è§å­—ä½“åç§°ï¼ˆé€šè¿‡matplotlibæŸ¥æ‰¾ï¼‰
        'SimHei', 'Microsoft YaHei', 'SimSun', 'KaiTi', 'FangSong',
        'Arial Unicode MS', 'DejaVu Sans'
    ]
    
    for font_path in font_candidates:
        if os.path.exists(font_path):
            return font_path
        
        # å°è¯•é€šè¿‡å­—ä½“åç§°æŸ¥æ‰¾
        try:
            import matplotlib.font_manager as fm
            if font_path in fm.findfont(fm.FontProperties(family=font_path)):
                return font_path
        except:
            continue
    
    # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›Noneï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
    return None
	
	
def extract_date_from_column_name(column_name):
    """ä»åˆ—åä¸­æå–æ—¥æœŸå­—ç¬¦ä¸²"""
    import re
    
    # å¸¸è§çš„æ—¥æœŸæ¨¡å¼
    date_patterns = [
        r'(\d{4}\.\d{1,2}\.\d{1,2})',  # 2023.01.15
        r'(\d{4}-\d{1,2}-\d{1,2})',    # 2023-01-15
        r'(\d{4}/\d{1,2}/\d{1,2})',    # 2023/01/15
        r'(\d{8})',                     # 20230115
        r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)' # 2023å¹´1æœˆ15æ—¥
    ]
    
    col_str = str(column_name)
    
    for pattern in date_patterns:
        match = re.search(pattern, col_str)
        if match:
            return match.group(1)
    
    return None

def parse_date(date_str):
    """è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºæ—¥æœŸå¯¹è±¡"""
    from datetime import datetime
    
    date_formats = [
        '%Y.%m.%d',
        '%Y-%m-%d', 
        '%Y/%m/%d',
        '%Y%m%d',
        '%Yå¹´%mæœˆ%dæ—¥'
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str, fmt).date()
        except:
            continue
    
    return None

	

# ========== ä¸»æµç¨‹ï¼ˆä¸Šä¼ ä¸å¤„ç†ï¼‰ ==========
# æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
uploaded_files = st.file_uploader("ä¸Šä¼ é—®è´¢Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼Œå¤šå¤©æ•°æ®ï¼›æŒ‰æ—¶é—´é¡ºåºä¸Šä¼ æˆ–æ–‡ä»¶åå«æ—¥æœŸï¼‰", type=["xlsx", "xls"], accept_multiple_files=True)

if not uploaded_files:
    st.info("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ª Excel æ–‡ä»¶ï¼ˆå¯ä»¥å¤šä¸ªæ‰¹æ¬¡ï¼‰ã€‚")
    st.stop()

# å­˜æ”¾ç»“æœçš„æ•°æ®ç»“æ„
all_results = []  # æ‰€æœ‰ç»“æœæ•°æ®
all_batch_dates = []  # æ‰€æœ‰æ‰¹æ¬¡æ—¥æœŸ
stock_trends = {}   # {code: [(date, passed_bool), ...]} è‚¡ç¥¨è¶‹åŠ¿è®°å½•
stock_concepts = {}  # è‚¡ç¥¨æ¦‚å¿µæ˜ å°„
daily_dfs = {}  # æ¯æ—¥æ•°æ®æ¡†å­˜å‚¨

# é€æ–‡ä»¶è¯»å–ä¸å¤„ç†
for uploaded_file in uploaded_files:
    try:
        # æ ¹æ®è¡¨å¤´è¡Œæ•°è¯»å–Excel
        if header_rows == 1:
            df = pd.read_excel(uploaded_file, header=0, skiprows=skip_rows)
            df.columns = [str(c).strip() for c in df.columns]
        else:
            # å¤„ç†å¤šè¡Œè¡¨å¤´
            df_raw = pd.read_excel(uploaded_file, header=None)
            header_df = df_raw.iloc[:header_rows].ffill(axis=1)
            df = df_raw.iloc[header_rows + skip_rows:].reset_index(drop=True)
            # æ„å»ºåˆå¹¶åˆ—å
            columns = []
            current_prefix = ""
            for col in header_df.values.T:
                col_strs = [str(x).strip() for x in col if str(x) != "nan"]
                if len(col_strs) == 0:
                    columns.append("")
                    continue
                if "æ”¶ç›˜ä»·" in col_strs[0]:
                    current_prefix = "æ”¶ç›˜ä»·"
                elif "5æ—¥å‡çº¿" in col_strs[0] or "å‡çº¿" in col_strs[0]:
                    current_prefix = "5æ—¥å‡çº¿"
                date_part = col_strs[-1] if len(col_strs) > 1 else col_strs[0]
                if current_prefix and "undefined" in col_strs[0]:
                    merged = f"{current_prefix}_{date_part}"
                else:
                    merged = "_".join(col_strs).strip("_")
                columns.append(merged)
            df.columns = columns
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶ {uploaded_file.name} å¤±è´¥: {e}")
        logging.exception(f"è¯»å–æ–‡ä»¶å¤±è´¥ {uploaded_file.name}: {e}")
        continue

    # åŸºç¡€æ•°æ®æ¸…æ´—
    try:
        for col in df.select_dtypes(include=['object']).columns:
            try:
                df[col] = df[col].astype(str).str.strip().replace({'nan': np.nan, 'None': np.nan})
            except Exception:
                logging.debug(f"strip failed for column {col}", exc_info=True)
        # æ›¿æ¢å„ç§ç©ºå€¼ç¬¦å·
        replace_symbols = ["-", "â€”", "ç©ºå€¼", "null", "None", "", "NaN", "--"]
        df.replace(replace_symbols, np.nan, inplace=True)
        # å¤„ç†æ•°å€¼åˆ—
        for col in df.columns:
            if df[col].dtype == object:
                try:
                    df[col] = df[col].astype(str).str.replace(',', '').str.replace(' ', '')
                except Exception:
                    pass
                try:
                    df[col] = pd.to_numeric(df[col], errors='ignore')
                except Exception:
                    pass
        # ç‰¹å®šæ•°å€¼åˆ—å¤„ç†
        for numeric_col in ["ç°ä»·(å…ƒ)", "æ–œç‡(%)", "å¹³å‡æ–œç‡"]:
            if numeric_col in df.columns:
                df[numeric_col] = pd.to_numeric(df[numeric_col], errors="coerce")
    except Exception as e:
        logging.exception(f"æ•°æ®æ¸…æ´—é˜¶æ®µå¼‚å¸¸: {e}")

    # Arrowå®‰å…¨åŒ–å¤„ç†
    try:
        df = make_arrow_safe(df)
    except Exception as e:
        logging.exception(f"make_arrow_safe failed: {e}")

    # è¯†åˆ«æ”¶ç›˜ä»·åˆ— & å‡çº¿åˆ—
    close_cols, ma_cols = [], []
    for c in df.columns[2:]:
        col_lower = str(c).lower()
        if "æ”¶ç›˜ä»·" in col_lower or "close" in col_lower:
            close_cols.append(c)
        elif "å‡çº¿" in col_lower or "ma" in col_lower:
            ma_cols.append(c)

    # ä»æ”¶ç›˜ä»·åˆ—åæå–æ—¥æœŸï¼ˆå–æœ€å¤§æ—¥æœŸä½œä¸ºæ‰¹æ¬¡æ—¥æœŸï¼‰
    dates = []
    for c in close_cols:
        parts = str(c).split('_')
        if len(parts) > 1:
            date_str_raw = parts[-1]
            date_str = date_str_raw.split(' [')[0].strip()
            # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
            for fmt in ("%Y.%m.%d", "%Y-%m-%d", "%Y%m%d", "%Y/%m/%d"):
                try:
                    date_obj = datetime.datetime.strptime(date_str, fmt).date()
                    dates.append(date_obj)
                    break
                except Exception:
                    continue
    if dates:
        batch_date = max(dates).strftime("%Y-%m-%d")
    else:
        # æ— æ³•æå–æ—¥æœŸæ—¶ä½¿ç”¨å½“å‰æ—¥æœŸ
        batch_date = datetime.date.today().strftime("%Y-%m-%d")
        st.warning(f"æ— æ³•ä»åˆ—åä¸­æå–æ—¥æœŸï¼ˆæ–‡ä»¶: {uploaded_file.name}ï¼‰ï¼Œä½¿ç”¨å½“å‰ç³»ç»Ÿæ—¥æœŸã€‚")
    all_batch_dates.append(batch_date)
    daily_dfs[batch_date] = df  # å­˜å‚¨æ¯æ—¥æ•°æ®

    # éå†æ¯åªè‚¡ç¥¨è¿›è¡Œåˆ†æ
    results = []
    for idx, row in df.iterrows():
        try:
            code = str(row[df.columns[0]]).strip()
            name = str(row[df.columns[1]]).strip()
        except Exception:
            continue

        # æå–æ¦‚å¿µä¿¡æ¯ - ä¿®å¤åŒè¡¨å¤´é—®é¢˜
        concept = "æœªçŸ¥"
        if concept_col_name in df.columns:
            concept_val = row.get(concept_col_name, "æœªçŸ¥")
            if pd.notna(concept_val):
                concept = str(concept_val).strip()
        else:
            # å°è¯•æŸ¥æ‰¾åŒ…å«"æ¦‚å¿µ"å…³é”®è¯çš„åˆ—
            concept_cols = [col for col in df.columns if "æ¦‚å¿µ" in str(col)]
            if concept_cols:
                concept_val = row.get(concept_cols[0], "æœªçŸ¥")
                if pd.notna(concept_val):
                    concept = str(concept_val).strip()
        
        if code not in stock_concepts:
            stock_concepts[code] = concept

        # æå–æ”¶ç›˜ä»·åºåˆ—
        closes = []
        for c in close_cols:
            val = row.get(c, np.nan)
            if pd.notna(val):
                val_str = str(val).replace(',', '').replace('â€”', '').replace('--', '').strip()
                if val_str in ["", "NaN", "None", "null"]:
                    continue
                try:
                    price = float(val_str)
                    if price > 0:
                        closes.append(price)
                except:
                    continue
        closes = closes[::-1]  # åè½¬é¡ºåºï¼ˆä»æ—§åˆ°æ–°ï¼‰
        closes = np.array(closes, dtype=float)

        # æå–å‡çº¿åºåˆ—
        ma_values = []
        if ma_cols:
            for c in ma_cols:
                val = row.get(c, np.nan)
                if pd.notna(val):
                    val_str = str(val).replace(',', '').replace('â€”', '').replace('--', '').strip()
                    if val_str in ["", "NaN", "None", "null"]:
                        continue
                    try:
                        ma = float(val_str)
                        if ma > 0:
                            ma_values.append(ma)
                    except:
                        continue
            ma_values = ma_values[::-1]
            ma_values = np.array(ma_values, dtype=float)
        else:
            # æ— å‡çº¿æ•°æ®æ—¶è®¡ç®—å±€éƒ¨å‡å€¼
            ma_days = min(5, len(closes))
            ma_values = np.array([np.mean(closes[max(0, i-ma_days+1):i+1]) for i in range(len(closes))]) if len(closes)>0 else np.array([])

        # åˆ¤æ–­æœ€è¿‘ close_days å¤©çš„è¶‹åŠ¿
        if len(closes) < close_days or len(ma_values) < close_days:
            closes_for_check = closes
            ma_for_check = ma_values
            is_up = False
            slope_perc = np.nan
            up_details = f"æ•°æ®ä¸è¶³: {len(closes)}/{close_days}"
        else:
            closes_for_check = closes[-close_days:]  # å–æœ€è¿‘close_dayså¤©
            ma_for_check = ma_values[-close_days:]
            # æ ¹æ®æ¨¡å¼åˆ¤æ–­æ˜¯å¦è¿ç»­ä¸Šæ¶¨
            if up_trend_mode == "strict":
                is_up, up_details = check_strict_continuous_up(closes_for_check, close_days)
            else:
                is_up, up_details = check_ma_above_continuous_up(closes_for_check, ma_for_check, close_days)
            # è®¡ç®—æ–œç‡
            x = np.arange(len(closes_for_check))
            try:
                slope, _ = np.polyfit(x, closes_for_check, 1)
                slope_perc = slope / closes_for_check.mean() * 100
            except Exception as e:
                slope_perc = np.nan
                logging.debug(f"è®¡ç®—æ–œç‡å¤±è´¥ï¼Œ{code}: {e}")

        # æ„å»ºä¸ç¬¦åˆåŸå› 
        reason = []
        if not is_up:
            reason.append(up_details if isinstance(up_details, str) else f"æœªè¿ç»­ä¸Šæ¶¨({close_days}å¤©)")
        if not np.isnan(slope_perc) and slope_perc < slope_threshold:
            reason.append(f"æ–œç‡è¿‡å°({slope_perc:.2f}%)")
        passed = len(reason) == 0  # æ˜¯å¦é€šè¿‡æ‰€æœ‰æ¡ä»¶

        # è®°å½•ç»“æœ
        results.append({
            "æ—¥æœŸ": batch_date,
            "è‚¡ç¥¨ä»£ç ": code,
            "è‚¡ç¥¨ç®€ç§°": name,
            "åˆ¤æ–­æ¨¡å¼": "ä¸¥æ ¼è¿ç»­ä¸Šæ¶¨" if up_trend_mode == "strict" else "5æ—¥å‡çº¿ä¸Š",
            "è¿ç»­ä¸Šæ¶¨": "âœ… æ˜¯" if is_up else "âŒ å¦",
            "æ–œç‡(%)": round(slope_perc, 3) if not np.isnan(slope_perc) else np.nan,
            "æ˜¯å¦ç¬¦åˆ": "âœ… æ˜¯" if passed else "âŒ å¦",
            "ä¸ç¬¦åˆåŸå› ": " | ".join(reason) if reason else "-"
        })

        # è®°å½•è‚¡ç¥¨è¶‹åŠ¿ï¼ˆç”¨äºå¤šå¤©åˆ†æï¼‰
        if code not in stock_trends:
            stock_trends[code] = []
        stock_trends[code].append((batch_date, passed))

    all_results.extend(results)

# æ’åºæ‰¹æ¬¡æ—¥æœŸ
all_batch_dates = sorted(set(all_batch_dates))



# ========== å…±åŒå‡ºç°è‚¡ç¥¨è¯¦ç»†åˆ†æï¼ˆå¯æŠ˜å ï¼‰ ==========
with st.expander("ğŸ”„ å…±åŒå‡ºç°è‚¡ç¥¨è¯¦ç»†åˆ†æ", expanded=True):
    if len(all_batch_dates) > 1:
        # æ„å»ºå‡ºç°æƒ…å†µçš„pivotè¡¨
        appear_df = pd.DataFrame(all_results)
        appear_df['è‚¡ç¥¨ä»£ç '] = appear_df['è‚¡ç¥¨ä»£ç '].astype(str).str.strip().str.upper()
        appear_df['æ—¥æœŸ'] = pd.to_datetime(appear_df['æ—¥æœŸ'], errors='coerce').dt.strftime('%Y-%m-%d')
        appear_pivot = appear_df.pivot_table(index='è‚¡ç¥¨ä»£ç ', columns='æ—¥æœŸ', values='æ˜¯å¦ç¬¦åˆ', aggfunc='size')
        appear_pivot = appear_pivot.reindex(columns=all_batch_dates)

        # åˆ¤æ–­ï¼šä¸¤ä¸ªæ–‡ä»¶éƒ½å‡ºç°ï¼ˆæ— è®ºæ˜¯å¦ç¬¦åˆï¼‰
        common_mask = appear_pivot.notna().all(axis=1)
        common_stocks = appear_pivot[common_mask].index.tolist()

        if len(common_stocks) == 0:
            st.info("ä¸¤ä¸ªæ–‡ä»¶ä¸­æ²¡æœ‰å…±åŒå‡ºç°çš„è‚¡ç¥¨ã€‚")
        else:
            st.success(f"**å…±åŒå‡ºç°ï¼š{len(common_stocks)} åªè‚¡ç¥¨**ï¼ˆä¸¤ä¸ªæ–‡ä»¶éƒ½æœ‰ï¼‰")

            # æ„å»ºè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯æ˜ å°„
            stock_info_map = {}
            stock_slope_map = {}
            
            # è·å–æœ€æ–°æ‰¹æ¬¡çš„æ–œç‡æ•°æ®
            latest_date = max(all_batch_dates) if all_batch_dates else None
            if latest_date:
                latest_results = [r for r in all_results if r['æ—¥æœŸ'] == latest_date]
                for result in latest_results:
                    code = result['è‚¡ç¥¨ä»£ç ']
                    stock_slope_map[code] = result['æ–œç‡(%)']
            
            # æ„å»ºå®Œæ•´çš„è‚¡ç¥¨ä¿¡æ¯æ˜ å°„
            for result in all_results:
                code = result['è‚¡ç¥¨ä»£ç ']
                if code not in stock_info_map:
                    stock_info_map[code] = {
                        'name': result['è‚¡ç¥¨ç®€ç§°'],
                        'concept': stock_concepts.get(code, 'æœªçŸ¥'),
                        'slope': stock_slope_map.get(code, np.nan)
                    }

            # åˆ›å»ºè¯¦ç»†çš„å…±åŒè‚¡ç¥¨ä¿¡æ¯è¡¨æ ¼
            common_stocks_details = []
            
            for code in common_stocks:
                info = stock_info_map.get(code, {})
                common_stocks_details.append({
                    'è‚¡ç¥¨ä»£ç ': code,
                    'è‚¡ç¥¨ç®€ç§°': info.get('name', 'æœªçŸ¥'),
                    'æ‰€å±æ¦‚å¿µ': info.get('concept', 'æœªçŸ¥'),
                    'æ–œç‡(%)': info.get('slope', np.nan)
                })
            
            # åˆ›å»ºDataFrameå¹¶æ’åºï¼ˆæŒ‰æ–œç‡é™åºï¼‰
            common_df = pd.DataFrame(common_stocks_details)
            if not common_df.empty and 'æ–œç‡(%)' in common_df.columns:
                common_df = common_df.sort_values('æ–œç‡(%)', ascending=False)
            
            # æ˜¾ç¤ºè¯¦ç»†çš„å…±åŒè‚¡ç¥¨è¡¨æ ¼
            st.dataframe(
                common_df.style.format({'æ–œç‡(%)': '{:.3f}'}),
                use_container_width=True
            )
            
            # æä¾›ä¸‹è½½åŠŸèƒ½
            csv = common_df.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è½½å…±åŒè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ CSV",
                data=csv,
                file_name=f"å…±åŒè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯_{pd.Timestamp('today').strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
            
            # ========== ä¿®æ­£ï¼šå…±åŒè‚¡ç¥¨è·¨æ–‡ä»¶æ—¶é—´è·¨åº¦æŠ˜çº¿å›¾ï¼ˆè‡ªåŠ¨æ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨ï¼‰ ==========
            st.markdown("---")
            st.subheader("ğŸ“Š å…±åŒè‚¡ç¥¨è·¨æ–‡ä»¶æ—¶é—´è·¨åº¦èµ°åŠ¿å›¾")
            
            # è‡ªåŠ¨æ˜¾ç¤ºæ‰€æœ‰å…±åŒè‚¡ç¥¨ï¼Œä¸å†ä½¿ç”¨ä¸‹æ‹‰æ¡†
            for i, selected_stock in enumerate(common_stocks):
                st.markdown(f"---")
                stock_name = stock_info_map.get(selected_stock, {}).get('name', 'æœªçŸ¥')
                st.markdown(f"### {i+1}. {selected_stock} - {stock_name}")
                
                # æ”¶é›†æ‰€æœ‰ä»·æ ¼æ•°æ®ç‚¹ï¼ˆæ—¥æœŸå’Œæ”¶ç›˜ä»·ï¼‰
                all_price_data = []  # å­˜å‚¨ (date, price, batch_date) å…ƒç»„
                
                # å¯¹æ¯ä¸ªæ‰¹æ¬¡æ—¥æœŸï¼Œä»å¯¹åº”çš„daily_dfsä¸­æå–è¯¥è‚¡ç¥¨çš„ä»·æ ¼æ•°æ®
                for batch_date in sorted(all_batch_dates):
                    df_batch = daily_dfs.get(batch_date)
                    if df_batch is not None:
                        # æ‰¾åˆ°è¯¥è‚¡ç¥¨åœ¨æ‰¹æ¬¡æ•°æ®ä¸­çš„è¡Œ
                        stock_row = None
                        for idx, row in df_batch.iterrows():
                            if str(row[df_batch.columns[0]]).strip() == selected_stock:
                                stock_row = row
                                break
                        
                        if stock_row is not None:
                            # æå–æ”¶ç›˜ä»·åˆ—
                            close_cols = [c for c in df_batch.columns if "æ”¶ç›˜ä»·" in str(c)]
                            if close_cols:
                                # æŒ‰æ—¶é—´é¡ºåºå¤„ç†æ¯ä¸ªæ”¶ç›˜ä»·åˆ—
                                for c in close_cols:
                                    val = stock_row.get(c, np.nan)
                                    if pd.notna(val):
                                        val_str = str(val).replace(',', '').replace('â€”', '').replace('--', '').strip()
                                        if val_str not in ["", "NaN", "None", "null"]:
                                            try:
                                                price = float(val_str)
                                                if price > 0:
                                                    # ä»åˆ—åæå–æ—¥æœŸ
                                                    col_name = str(c)
                                                    date_str = extract_date_from_column_name(col_name)
                                                    if date_str:
                                                        # è½¬æ¢ä¸ºæ—¥æœŸå¯¹è±¡
                                                        date_obj = parse_date(date_str)
                                                        if date_obj:
                                                            # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆå‘¨ä¸€è‡³å‘¨äº”ï¼‰
                                                            if date_obj.weekday() < 5:  # 0-4 è¡¨ç¤ºå‘¨ä¸€åˆ°å‘¨äº”
                                                                all_price_data.append({
                                                                    'date': date_obj,
                                                                    'price': price,
                                                                    'batch': batch_date,
                                                                    'column_name': col_name
                                                                })
                                            except:
                                                continue
                
                # æŒ‰æ—¥æœŸæ’åºå¹¶å»é‡
                if all_price_data:
                    # æŒ‰æ—¥æœŸæ’åº
                    all_price_data.sort(key=lambda x: x['date'])
                    
                    # å»é‡ï¼šåŒä¸€å¤©åªä¿ç•™ä¸€ä¸ªä»·æ ¼ï¼ˆå–æœ€åä¸€ä¸ªï¼‰
                    unique_dates = {}
                    for item in all_price_data:
                        date_key = item['date'].strftime('%Y-%m-%d')
                        unique_dates[date_key] = item
                    
                    all_price_data = list(unique_dates.values())
                    all_price_data.sort(key=lambda x: x['date'])
                    
                    # å‡†å¤‡ç»˜å›¾æ•°æ®
                    dates = [item['date'] for item in all_price_data]
                    prices = [item['price'] for item in all_price_data]
                    batches = [item['batch'] for item in all_price_data]
                    
                    # åˆ›å»ºæŠ˜çº¿å›¾
                    fig, ax = plt.subplots(figsize=(12, 6))
                    
                    # è®¾ç½®ä¸­æ–‡å­—ä½“
                    chinese_font = get_chinese_font()
                    if chinese_font:
                        plt.rcParams['font.sans-serif'] = [chinese_font] + plt.rcParams['font.sans-serif']
                        plt.rcParams['axes.unicode_minus'] = False
                    
                    # ç»˜åˆ¶ä¸»æŠ˜çº¿
                    ax.plot(dates, prices, marker='o', linewidth=2, color='blue', markersize=6)
                    
                    # ç”¨ä¸åŒé¢œè‰²æ ‡è®°ä¸åŒæ‰¹æ¬¡çš„æ•°æ®ç‚¹
                    unique_batches = list(set(batches))
                    colors = ['red', 'green', 'orange', 'purple', 'brown']
                    batch_colors = {}
                    
                    for i, batch in enumerate(unique_batches):
                        batch_colors[batch] = colors[i % len(colors)]
                    
                    # æ ‡è®°ä¸åŒæ‰¹æ¬¡çš„æ•°æ®ç‚¹
                    for i, (date, price, batch) in enumerate(zip(dates, prices, batches)):
                        color = batch_colors[batch]
                        # åªåœ¨ç¬¬ä¸€æ¬¡å‡ºç°è¯¥æ‰¹æ¬¡æ—¶æ·»åŠ å›¾ä¾‹
                        label = batch if batch not in [batches[j] for j in range(i)] else ""
                        ax.scatter(date, price, color=color, s=80, zorder=5, label=label)
                    
                    # æ·»åŠ ä»·æ ¼æ ‡ç­¾ï¼ˆæ¯éš”å‡ ä¸ªç‚¹æ˜¾ç¤ºä¸€æ¬¡ï¼Œé¿å…å¤ªæ‹¥æŒ¤ï¼‰
                    n = max(1, len(dates) // 8)  # æ¯8ä¸ªç‚¹å·¦å³æ˜¾ç¤ºä¸€ä¸ªæ ‡ç­¾
                    for i, (date, price) in enumerate(zip(dates, prices)):
                        if i % n == 0 or i == len(dates) - 1:
                            ax.annotate(f'{price:.2f}', 
                                      (date, price),
                                      textcoords="offset points",
                                      xytext=(0, 10),
                                      ha='center',
                                      fontsize=8,
                                      bbox=dict(boxstyle="round,pad=0.2", facecolor="white", alpha=0.7))
                    
                    # å›¾è¡¨ç¾åŒ–
                    ax.set_title(f'{selected_stock} {stock_name} - ä»·æ ¼èµ°åŠ¿å›¾ï¼ˆä»…æ˜¾ç¤ºäº¤æ˜“æ—¥ï¼‰', 
                               fontsize=14, fontweight='bold')
                    ax.set_xlabel('æ—¥æœŸ', fontsize=10)
                    ax.set_ylabel('æ”¶ç›˜ä»· (å…ƒ)', fontsize=10)
                    
                    # è®¾ç½®Xè½´æ—¥æœŸæ ¼å¼
                    ax.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))
                    # æ ¹æ®æ•°æ®ç‚¹æ•°é‡è°ƒæ•´åˆ»åº¦é—´éš”
                    if len(dates) > 10:
                        interval = max(1, len(dates) // 10)
                        ax.xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=interval))
                    else:
                        ax.xaxis.set_major_locator(plt.matplotlib.dates.DayLocator(interval=1))
                    
                    plt.xticks(rotation=45)
                    
                    # æ·»åŠ å›¾ä¾‹
                    handles, labels = ax.get_legend_handles_labels()
                    by_label = dict(zip(labels, handles))  # å»é‡
                    if by_label:
                        ax.legend(by_label.values(), by_label.keys(), title="æ•°æ®æ‰¹æ¬¡", fontsize=8)
                    
                    ax.grid(True, alpha=0.3)
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close()
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("äº¤æ˜“æ—¥æ•°é‡", f"{len(dates)}ä¸ª")
                    
                    with col2:
                        date_range = f"{dates[0].strftime('%Y-%m-%d')} è‡³ {dates[-1].strftime('%Y-%m-%d')}"
                        st.metric("æ—¶é—´è·¨åº¦", date_range)
                    
                    with col3:
                        start_price = prices[0]
                        end_price = prices[-1]
                        total_change_pct = ((end_price - start_price) / start_price * 100) if start_price > 0 else 0
                        st.metric("æœŸé—´æ¶¨è·Œå¹…", f"{total_change_pct:+.2f}%")
                    
                    with col4:
                        st.metric("æ¶‰åŠæ‰¹æ¬¡", f"{len(unique_batches)}ä¸ª")
                    
                    # æ˜¾ç¤ºè¯¦ç»†æ•°æ®è¡¨æ ¼ï¼ˆå¯æŠ˜å ï¼‰
                    with st.expander(f"ğŸ“ˆ æŸ¥çœ‹ {selected_stock} è¯¦ç»†ä»·æ ¼æ•°æ®", expanded=False):
                        # åˆ›å»ºè¯¦ç»†æ•°æ®è¡¨æ ¼
                        detail_data = []
                        for item in all_price_data:
                            detail_data.append({
                                'æ—¥æœŸ': item['date'].strftime('%Y-%m-%d'),
                                'æ”¶ç›˜ä»·': f"{item['price']:.2f}",
                                'æ•°æ®æ‰¹æ¬¡': item['batch'],
                                'æ˜ŸæœŸ': ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][item['date'].weekday()]
                            })
                        
                        detail_df = pd.DataFrame(detail_data)
                        st.dataframe(
                            detail_df,
                            use_container_width=True
                        )
                        
                        # æä¾›ä»·æ ¼æ•°æ®ä¸‹è½½
                        csv_price = detail_df.to_csv(index=False, encoding="utf-8-sig")
                        st.download_button(
                            f"ä¸‹è½½ {selected_stock} ä»·æ ¼æ•°æ® CSV",
                            data=csv_price,
                            file_name=f"{selected_stock}_ä»·æ ¼æ•°æ®_{pd.Timestamp('today').strftime('%Y%m%d')}.csv",
                            mime="text/csv",
                            key=f"download_{selected_stock}"
                        )
                else:
                    st.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {selected_stock} åœ¨å¤šä¸ªæ–‡ä»¶ä¸­çš„å®Œæ•´ä»·æ ¼æ•°æ®")
    else:
        st.info("éœ€è¦è‡³å°‘ä¸¤ä¸ªæ‰¹æ¬¡çš„æ–‡ä»¶æ‰èƒ½è¿›è¡Œå…±åŒå‡ºç°åˆ†æã€‚")
		

# ========== ç¬¦åˆæ¡ä»¶è‚¡ç¥¨èµ°åŠ¿å›¾ï¼ˆå¯æŠ˜å ï¼‰ ==========
with st.expander("ğŸ“ˆ ç¬¦åˆæ¡ä»¶è‚¡ç¥¨èµ°åŠ¿å›¾ï¼ˆæœ€æ–°æ‰¹æ¬¡ - æŒ‰æ–œç‡é™åºæ’åˆ—ï¼‰", expanded=False):
    latest_date = max(all_batch_dates) if all_batch_dates else None
    if latest_date:
        # ç­›é€‰æœ€æ–°æ‰¹æ¬¡ä¸­ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œå¹¶æŒ‰æ–œç‡é™åºæ’åº
        passed_stocks_df = pd.DataFrame(all_results)
        passed_stocks = passed_stocks_df[
            (passed_stocks_df["æ—¥æœŸ"] == latest_date) & 
            (passed_stocks_df["æ˜¯å¦ç¬¦åˆ"] == "âœ… æ˜¯")
        ].sort_values("æ–œç‡(%)", ascending=False)  # æŒ‰æ–œç‡ä»å¤§åˆ°å°æ’åº
        
        if not passed_stocks.empty:
            st.success(f"æœ€æ–°æ‰¹æ¬¡ç¬¦åˆæ¡ä»¶è‚¡ç¥¨æ•°é‡ï¼š{len(passed_stocks)} åªï¼ŒæŒ‰æ–œç‡ä»é«˜åˆ°ä½å±•ç¤º")
            
            # æ˜¾ç¤ºæ’åºåçš„è‚¡ç¥¨åˆ—è¡¨
            st.write("### è‚¡ç¥¨æ’åºåˆ—è¡¨ï¼ˆæ–œç‡ä»é«˜åˆ°ä½ï¼‰")
            sorted_list = passed_stocks[["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨ç®€ç§°", "æ–œç‡(%)"]].reset_index(drop=True)
            st.dataframe(sorted_list.style.format({'æ–œç‡(%)': '{:.3f}%'}), use_container_width=True)
            
            df_latest = daily_dfs[latest_date]
            stock_data_map_latest = build_stock_data_map_from_df(df_latest)
            
            # æŒ‰æ’åºåçš„é¡ºåºç»˜åˆ¶èµ°åŠ¿å›¾
            for idx, (_, row) in enumerate(passed_stocks.iterrows(), 1):
                code = row["è‚¡ç¥¨ä»£ç "]
                name = row["è‚¡ç¥¨ç®€ç§°"]
                slope = row["æ–œç‡(%)"]
                
                st.markdown(f"---")
                st.markdown(f"### #{idx} - {code} {name} (æ–œç‡: {slope:.3f}%)")
                
                if code in stock_data_map_latest:
                    closes = stock_data_map_latest[code]['closes']
                    ma_values = stock_data_map_latest[code]['ma_values']
                    
                    if len(closes) >= 2:
                        # åˆ›å»ºåŒå­å›¾
                        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
                        
                        # å·¦å›¾ï¼šä»·æ ¼èµ°åŠ¿
                        ax1.plot(range(len(closes)), closes, marker="o", linewidth=2, color='blue', label='æ”¶ç›˜ä»·')
                        ax1.axhline(np.mean(closes), linestyle='--', linewidth=1.5, 
                                   label=f'{len(closes)}æ—¥å‡çº¿', alpha=0.8, color='orange')
                        
                        # æ·»åŠ ä»·æ ¼æ ‡æ³¨
                        for i, price in enumerate(closes):
                            ax1.annotate(f'{price:.2f}', (i, price), 
                                       textcoords="offset points", xytext=(0, 8), 
                                       ha='center', fontsize=8)
                        
                        # å¦‚æœä½¿ç”¨å‡çº¿æ¨¡å¼ï¼Œç»˜åˆ¶å‡çº¿
                        if up_trend_mode == "ma_above" and len(ma_values) == len(closes):
                            ax1.plot(range(len(closes)), ma_values, marker="s", linestyle="-", 
                                   label='5æ—¥å‡çº¿', linewidth=1.5, color='red')
                        
                        ax1.set_title(f"{code} {name}\næ–œç‡: {slope:.3f}% (æœ€è¿‘{close_days}å¤©)", fontsize=14)
                        ax1.legend()
                        ax1.grid(True, alpha=0.3)
                        ax1.set_xlabel("äº¤æ˜“æ—¥")
                        ax1.set_ylabel("ä»·æ ¼")

                        # å³å›¾ï¼šæ¶¨è·Œå¹…æŸ±çŠ¶å›¾
                        price_changes = safe_calculate_price_changes(closes)
                        if price_changes:
                            colors = ['green' if x > 0 else 'red' for x in price_changes]
                            bars = ax2.bar(range(1, len(closes)), price_changes, color=colors, alpha=0.7)
                            
                            # æ·»åŠ æ¶¨è·Œå¹…æ ‡æ³¨
                            for bar, ch in zip(bars, price_changes):
                                h = bar.get_height()
                                ax2.text(bar.get_x() + bar.get_width()/2., 
                                        h + (0.5 if h >= 0 else -0.5), 
                                        f'{ch:+.2f}%', 
                                        ha='center', va='bottom' if h >= 0 else 'top', 
                                        fontsize=8, fontweight='bold')
                            
                            ax2.axhline(0, color='black', linewidth=0.8)
                            ax2.set_title("æ¯æ—¥æ¶¨è·Œå¹…", fontsize=14)
                            ax2.set_xlabel("äº¤æ˜“æ—¥")
                            ax2.set_ylabel("æ¶¨è·Œå¹…(%)")
                            ax2.grid(True, alpha=0.3)
                        else:
                            ax2.text(0.5, 0.5, "æ— æ¶¨è·Œå¹…æ•°æ®", 
                                   ha='center', va='center', transform=ax2.transAxes, fontsize=12)
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close()
                        
                        # æ˜¾ç¤ºè¯¥è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("å½“å‰ä»·æ ¼", f"{closes[-1]:.2f}" if len(closes) > 0 else "N/A")
                        with col2:
                            start_price = closes[0] if len(closes) > 0 else 0
                            end_price = closes[-1] if len(closes) > 0 else 0
                            total_change = ((end_price - start_price) / start_price * 100) if start_price > 0 else 0
                            st.metric("æ€»æ¶¨è·Œå¹…", f"{total_change:+.2f}%")
                        with col3:
                            st.metric("åˆ†æå¤©æ•°", f"{len(closes)}å¤©")
                else:
                    st.warning(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {code} çš„è¯¦ç»†æ•°æ®")
        else:
            st.info("æœ€æ–°æ‰¹æ¬¡æ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ã€‚")
    else:
        st.warning("æ— æ³•ç¡®å®šæœ€æ–°æ‰¹æ¬¡æ—¥æœŸ")

# ========== æ‰€å±æ¦‚å¿µæ¶¨å¹…æ’åï¼ˆå¯æŠ˜å ï¼‰ ==========
with st.expander("ğŸ“Š æ‰€å±æ¦‚å¿µæ¶¨å¹…æ’åï¼ˆè·¨æ‰¹æ¬¡ Â· å¤šæ¦‚å¿µæ‹†åˆ†ï¼‰", expanded=False):
    if not daily_dfs:
        st.warning("è¯·å…ˆä¸Šä¼  Excel æ–‡ä»¶å¹¶è§£ææ‰¹æ¬¡æ•°æ®ã€‚")
    else:
        stock_tracker = {}  # è·Ÿè¸ªæ¯åªè‚¡ç¥¨çš„é¦–å°¾ä»·æ ¼

        # æŒ‰æ—¥æœŸæ’åºå¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        for date_str, df in sorted(daily_dfs.items()):
            close_cols = [c for c in df.columns if "æ”¶ç›˜ä»·" in str(c)]
            if not close_cols: continue
            close_col = close_cols[-1]  # ä½¿ç”¨æœ€æ–°çš„æ”¶ç›˜ä»·åˆ—
            code_col = df.columns[0]
            concept_col = "æ‰€å±æ¦‚å¿µ"

            # æ£€æŸ¥æ¦‚å¿µåˆ—æ˜¯å¦å­˜åœ¨
            if concept_col not in df.columns:
                # å°è¯•æŸ¥æ‰¾åŒ…å«"æ¦‚å¿µ"å…³é”®è¯çš„åˆ—
                concept_cols = [col for col in df.columns if "æ¦‚å¿µ" in str(col)]
                if concept_cols:
                    concept_col = concept_cols[0]
                    st.warning(f"æ‰¹æ¬¡ {date_str} ä½¿ç”¨ '{concept_col}' ä½œä¸ºæ¦‚å¿µåˆ—")
                else:
                    st.warning(f"æ‰¹æ¬¡ {date_str} ç¼ºå°‘æ¦‚å¿µåˆ—ï¼Œæ ‡è®°ä¸º 'æœªçŸ¥'")
                    df[concept_col] = "æœªçŸ¥"

            # å¤„ç†æ¯åªè‚¡ç¥¨
            for _, row in df.iterrows():
                code = str(row[code_col]).strip()
                try:
                    price = float(str(row[close_col]).replace(',', ''))
                except:
                    continue

                concept_str = str(row[concept_col]).strip()
                if concept_str in ['', 'nan', 'NaN'] or pd.isna(row[concept_col]):
                    concept_str = "æœªçŸ¥"

                # è·Ÿè¸ªè‚¡ç¥¨ä»·æ ¼å˜åŒ–
                if code not in stock_tracker:
                    stock_tracker[code] = {
                        "first_price": price, "last_price": price,
                        "concept": concept_str,
                        "first_date": date_str, "last_date": date_str
                    }
                else:
                    stock_tracker[code]["last_price"] = price
                    stock_tracker[code]["last_date"] = date_str

        # è®¡ç®—æ¯åªè‚¡ç¥¨çš„æ¶¨å¹…
        gain_records = []
        for code, data in stock_tracker.items():
            if data["first_price"] == 0: continue
            gain_pct = (data["last_price"] - data["first_price"]) / data["first_price"] * 100
            gain_records.append({
                "è‚¡ç¥¨ä»£ç ": code,
                "æ‰€å±æ¦‚å¿µ": data["concept"],  # åŸå§‹å­—ç¬¦ä¸²ï¼Œå¦‚ "æ³¨å†Œåˆ¶æ¬¡æ–°è‚¡;ä¸“ç²¾ç‰¹æ–°;..."
                "èµ·å§‹ä»·": round(data["first_price"], 2),
                "ç»“æŸä»·": round(data["last_price"], 2),
                "æ¶¨å¹…%": round(gain_pct, 2)
            })

        if not gain_records:
            st.info("æœªæ‰¾åˆ°è·¨æ‰¹æ¬¡æœ‰å®Œæ•´é¦–å°¾ä»·æ ¼çš„è‚¡ç¥¨æ•°æ®ã€‚")
        else:
            gain_df = pd.DataFrame(gain_records)

            # === å…³é”®ï¼šæ‹†åˆ†å¤šæ¦‚å¿µï¼ˆæ”¯æŒ 301585 ç­‰ï¼‰===
            gain_df['æ‰€å±æ¦‚å¿µ'] = gain_df['æ‰€å±æ¦‚å¿µ'].astype(str)
            gain_df = gain_df.assign(æ‰€å±æ¦‚å¿µ=gain_df['æ‰€å±æ¦‚å¿µ'].str.split(';')).explode('æ‰€å±æ¦‚å¿µ')
            gain_df['æ‰€å±æ¦‚å¿µ'] = gain_df['æ‰€å±æ¦‚å¿µ'].str.strip()
            gain_df = gain_df[gain_df['æ‰€å±æ¦‚å¿µ'].str.len() > 0]
            gain_df = gain_df[~gain_df['æ‰€å±æ¦‚å¿µ'].isin(['', 'nan', 'æœªçŸ¥', 'NaN'])]
            # =========================================

            # æŒ‰æ¦‚å¿µèšåˆè®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            ranking = (
                gain_df.groupby("æ‰€å±æ¦‚å¿µ")
                .agg(
                    è‚¡ç¥¨æ•°é‡=("è‚¡ç¥¨ä»£ç ", "nunique"),
                    å¹³å‡æ¶¨å¹…=("æ¶¨å¹…%", "mean"),
                    æœ€é«˜æ¶¨å¹…=("æ¶¨å¹…%", "max"),
                    æœ€ä½æ¶¨å¹…=("æ¶¨å¹…%", "min")
                )
                .round(2)
                .sort_values("å¹³å‡æ¶¨å¹…", ascending=False)
                .reset_index()
            )

            # å±•ç¤ºæ’åç»“æœ
            st.dataframe(
                ranking.style
                .bar(subset=["å¹³å‡æ¶¨å¹…"], color="#5fba7d")  # å¹³å‡æ¶¨å¹…æ¡å½¢å›¾
                .bar(subset=["è‚¡ç¥¨æ•°é‡"], color="#4c78a8")   # è‚¡ç¥¨æ•°é‡æ¡å½¢å›¾
                .format({"å¹³å‡æ¶¨å¹…": "{:.2f}%", "æœ€é«˜æ¶¨å¹…": "{:.2f}%", "æœ€ä½æ¶¨å¹…": "{:.2f}%"}),
                use_container_width=True
            )

            # æä¾›ä¸‹è½½åŠŸèƒ½
            csv = ranking.to_csv(index=False, encoding="utf-8-sig")
            st.download_button(
                "ä¸‹è½½ æ‰€å±æ¦‚å¿µæ¶¨å¹…æ’å CSV",
                data=csv,
                file_name=f"æ‰€å±æ¦‚å¿µæ¶¨å¹…æ’å_{pd.Timestamp('today').strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )

            # æ˜ç»†æŸ¥çœ‹ï¼ˆæ”¯æŒæœç´¢ç‰¹å®šè‚¡ç¥¨ï¼‰
            with st.expander("æŸ¥çœ‹ä¸ªè‚¡æ˜ç»†ï¼ˆæ”¯æŒæœç´¢ 301585 ç­‰ï¼‰"):
                search_code = st.text_input("æœç´¢è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 301585ï¼‰", "")
                detail_df = gain_df[gain_df["è‚¡ç¥¨ä»£ç "].str.contains(search_code, na=False)] if search_code else gain_df
                st.dataframe(
                    detail_df[["è‚¡ç¥¨ä»£ç ", "æ‰€å±æ¦‚å¿µ", "èµ·å§‹ä»·", "ç»“æŸä»·", "æ¶¨å¹…%"]].sort_values("æ¶¨å¹…%", ascending=False),
                    use_container_width=True
                )